# -*- coding: utf-8 -*-
"""DawaniSonam_HW2_Task3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m6sw8koSpBLMcFK8oEK9KxiWpHU0S7_J

Task 3: For the data from the Quantitative.csv file â€“ find outliers (state clearly what method you picked, and provide some short rationale for your choice if possible), and implement clamp transformation on them. Then normalize the data (state clearly what method you picked, and provide your rationale if possible). Now, generate box plots and SPLOMs again and compare with the related

Page 1 of 2 results from Task 2. Discuss what you observed, and try to provide explanations for the things you noticed. Save the results of your data transformations in a new QTransferred.csv file. In this file you need to store 2 new columns per each original attribute that you processed. The 1 st column should be called OriginalAtrributeName_ClampedValues, and 2 nd column should be named OriginalAtrributeName_ClampedNormalizedValues. Make sure to process all attributes from the Quantitative.csv file in this way.
"""

#Task3
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tabulate import tabulate

#Copying Task 1, so that even if Task 1 is not executed before this, Task 2 can have Quantitative.csv
#Task 1
dataPreP = pd.read_csv("dataPreP.csv") 
Quantitative=dataPreP[['Attr 4','Attr 5','Attr 6','Attr 7','Attr 8','Attr 9','Attr 10','Attr 11','Attr 12',]]
Quantitative.to_csv('Quantitative.csv',index=False)
Others=dataPreP[['Attr 0','Attr 1','Attr 2','Attr 3','Labels',]]
Others.to_csv('Others.csv',index=False)
#Task 1 ends


Quantitative=pd.read_csv("Quantitative.csv") 
Quantitative_DQR=Quantitative.describe().T
missPer=Quantitative[['Attr 4','Attr 5','Attr 6','Attr 7','Attr 8','Attr 9','Attr 10','Attr 11','Attr 12']].isna().sum()/Quantitative.count()
card=Quantitative.nunique()
Quantitative_DQR['missPer']=missPer
Quantitative_DQR['card']=card
cols=['count', 'missPer','card','min','25%','mean', '50%','75%', 'max','std']
Quantitative_DQR=Quantitative_DQR[cols] #rearranging

#compares the gap between the median, minimum , maximum, 1st quartile, 3rd quartile 
Quantitative_gapDF=Quantitative_DQR[['min','25%','50%','75%','max']]
Quantitative_gapDF['right_outlier_measure']=( (Quantitative_gapDF['max']-Quantitative_gapDF['75%']) -(Quantitative_gapDF['75%']-Quantitative_gapDF['50%']))/(Quantitative_gapDF['75%']-Quantitative_gapDF['25%'])
Quantitative_gapDF['left_outlier_measure']=( (Quantitative_gapDF['25%']-Quantitative_gapDF['min']) -(Quantitative_gapDF['50%']-Quantitative_gapDF['25%']))/(Quantitative_gapDF['75%']-Quantitative_gapDF['25%'])
print('Quantitative_gapDF:')
print(tabulate(Quantitative_gapDF, headers='keys', tablefmt='psql'))

def ZScore(RawDataFrame):
  threshold=1.92
  outliers=pd.DataFrame()
  cols=RawDataFrame.columns
  for col in cols:
    listv=[]
    RawMean = RawDataFrame[col].mean()
    RawStd =RawDataFrame[col].std()
    for value in RawDataFrame[col]:
      z_score= (value - RawMean)/RawStd 
      if abs(z_score) > threshold:
        listv.append(value)
    outliers[col]=pd.Series(listv)
  return outliers

ZScore_outliers=ZScore(Quantitative)
print('ZScore_outliers:')
print(tabulate(ZScore_outliers, headers='keys', tablefmt='psql'))

print('Outliers Attritube wise count:')
print(ZScore_outliers.count())


def clampT(Quantitative):
  cols=Quantitative.columns
  for col in cols:
    cLower = (list(Quantitative[col].quantile([0.25]))[0]) - (1.5* ( (list(Quantitative[col].quantile([0.75]))[0]) - (list(Quantitative[col].quantile([0.25]))[0]) )  )
    cUpper = (list(Quantitative[col].quantile([0.75]))[0]) + (1.5* ( (list(Quantitative[col].quantile([0.75]))[0]) - (list(Quantitative[col].quantile([0.25]))[0]) )  )
    Quantitative[col]=Quantitative[col].apply(lambda x: cLower if x<cLower else x)
    Quantitative[col]=Quantitative[col].apply(lambda x: cUpper if x>cUpper else x)
  return Quantitative

Quantitative_clampT=clampT(Quantitative)
print('Quantitative_clampT: ')
print(tabulate(Quantitative_clampT, headers='keys', tablefmt='psql'))

#Normalization - range based because we have already removed outliers, which impact range based normalization ...and for standardization the data should be normally distributed
#taking range as -1 to 1

desiredRange_Low=-1
desiredRange_High=1

def rangeBasedNormalization(Quantitative):
  cols=Quantitative.columns
  for col in cols:
    colMax=Quantitative[col].max()
    colMin=Quantitative[col].min()
    Quantitative[col]=Quantitative[col].apply( lambda value: (((value-colMin)/(colMax-colMin))*(desiredRange_High-desiredRange_Low))+desiredRange_Low )
  return Quantitative

print('Quantitative_clampT_normalized: ')
Quantitative_clampT_normalized=rangeBasedNormalization(Quantitative_clampT)
print(tabulate(Quantitative_clampT_normalized, headers='keys', tablefmt='psql'))

QTransferred=pd.DataFrame(Quantitative)
cols=QTransferred.columns
for col in cols:
  col_i=QTransferred.columns.get_loc(col)
  Clamped_ColName=col+'_ClampedValues'
  ClampedNormalized_ColName=col+'_ClampedNormalizedValues'
  list_clampedValues=Quantitative_clampT[col]
  list_ClampedNormalizedValues=Quantitative_clampT_normalized[col]
  QTransferred.insert(col_i+1, Clamped_ColName , list_clampedValues, True)
  QTransferred.insert(col_i+2, ClampedNormalized_ColName , list_clampedValues, True)

QTransferred.to_csv('QTransferred.csv',index=False)

print('Box Plot:')
boxplot = Quantitative_clampT_normalized.boxplot(figsize=(10,10))

print('SPLOM:')
sns.pairplot(Quantitative_clampT_normalized).savefig('Quantitative_clampT_normalized.png')